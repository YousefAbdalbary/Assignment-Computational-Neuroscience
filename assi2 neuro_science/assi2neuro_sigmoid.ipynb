{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward phase \n",
      "prob of classs o1 : 0.6611228326800431\n",
      "prob of classs o2 : 0.6444006652388495\n",
      "It is class o1\n",
      "\n",
      "\n",
      "Weights:\n",
      "W1: 0.14985501913711796, W2: -0.292567632175021, W3: 0.42227068779932064, W4: -0.41414018527406915\n",
      "W5: -0.13898332125894164, W6: 0.08758736583452731, W7: -0.32319992465152425, W8: 0.15224376885318436\n",
      "\n",
      "\n",
      "Backpropagation\n",
      "Updated Weights:\n",
      "W1: 0.1498864432165554, W2: -0.29250478401614616, W3: 0.42227494015625566, W4: -0.4141316805601991\n",
      "W5: -0.09395604774523675, W6: 0.13263985238062592, W7: -0.3476442513169766, W8: 0.12778575458126673\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + 2.718281828459045 ** -x)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def random_weight():\n",
    "    return random.uniform(-.5, .5)\n",
    "\n",
    "def weighted_sum(inputs, weights, bias):\n",
    "    return sum(i * w for i, w in zip(inputs, weights)) + bias\n",
    "\n",
    "w1, w2, w3, w4 = random_weight(), random_weight(), random_weight(), random_weight()\n",
    "w5, w6, w7, w8 = random_weight(), random_weight(), random_weight(), random_weight()\n",
    "\n",
    "i1, i2 = .05, .1\n",
    "b1, b2 = .5, .7\n",
    "learning_rate = 0.5  \n",
    "\n",
    "# Hidden layer \n",
    "net_h1 = weighted_sum([i1, i2], [w1, w2], b1) \n",
    "out_h1 = sigmoid(net_h1)\n",
    "net_h2 = weighted_sum([i1, i2], [w3, w4], b1) \n",
    "out_h2 = sigmoid(net_h2)\n",
    "\n",
    "# Output layer \n",
    "net_o1 = weighted_sum([out_h1, out_h2], [w5, w6], b2) \n",
    "out_o1 = sigmoid(net_o1)\n",
    "net_o2 = weighted_sum([out_h1, out_h2], [w7, w8], b2) \n",
    "out_o2 = sigmoid(net_o2)\n",
    "\n",
    "print(\"Forward phase \")\n",
    "print(f\"prob of classs o1 : {out_o1}\")\n",
    "print(f\"prob of classs o2 : {out_o2}\")\n",
    "print(\"It is class o1\") if (out_o1 > out_o2) else print(\"It is class o2\")\n",
    "print(\"\\n\\nWeights:\")\n",
    "print(f\"W1: {w1}, W2: {w2}, W3: {w3}, W4: {w4}\")\n",
    "print(f\"W5: {w5}, W6: {w6}, W7: {w7}, W8: {w8}\")\n",
    "\n",
    "actual_o1, actual_o2 = 0.01, 0.99 \n",
    "\n",
    "error_o1 = .5 * (out_o1 - actual_o1) ** 2\n",
    "error_o2 = .5 * (out_o2 - actual_o2) ** 2\n",
    "total_error = error_o1 + error_o2\n",
    "\n",
    "delta_o1 = -(actual_o1 - out_o1) * sigmoid_derivative(out_o1)\n",
    "delta_o2 = -(actual_o2 - out_o2) * sigmoid_derivative(out_o2)\n",
    "\n",
    "delta_h1 = (delta_o1 * w5 + delta_o2 * w7) * sigmoid_derivative(out_h1)\n",
    "delta_h2 = (delta_o1 * w6 + delta_o2 * w8) * sigmoid_derivative(out_h2)\n",
    "\n",
    "w1 += learning_rate * delta_h1 * i1\n",
    "w2 += learning_rate * delta_h1 * i2\n",
    "w3 += learning_rate * delta_h2 * i1\n",
    "w4 += learning_rate * delta_h2 * i2\n",
    "\n",
    "w5 += learning_rate * delta_o1 * out_h1\n",
    "w6 += learning_rate * delta_o1 * out_h2\n",
    "w7 += learning_rate * delta_o2 * out_h1\n",
    "w8 += learning_rate * delta_o2 * out_h2\n",
    "\n",
    "print('\\n\\nBackpropagation')\n",
    "print(\"Updated Weights:\")\n",
    "print(f\"W1: {w1}, W2: {w2}, W3: {w3}, W4: {w4}\")\n",
    "print(f\"W5: {w5}, W6: {w6}, W7: {w7}, W8: {w8}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
