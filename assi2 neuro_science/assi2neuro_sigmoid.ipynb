{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward phase \n",
      "prob of classs o1 : 0.7513650695523157\n",
      "prob of classs o2 : 0.7729284653214625\n",
      "It is class o2\n",
      "\n",
      "\n",
      "Weights:\n",
      "W1: 0.15, W2: 0.2, W3: 0.25, W4: 0.3\n",
      "W5: 0.4, W6: 0.45, W7: 0.5, W8: 0.55\n",
      "\n",
      "\n",
      "Backpropagation\n",
      "Updated Weights:\n",
      "W1: 0.1497807161327628, W2: 0.19956143226552567, W3: 0.24975114363236958, W4: 0.29950228726473915\n",
      "W5: 0.35891647971788465, W6: 0.4086661860762334, W7: 0.5113012702387375, W8: 0.5613701211079891\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + 2.718281828459045 ** -x)\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "def weighted_sum(inputs, weights, bias):\n",
    "    return sum(i * w for i, w in zip(inputs, weights)) + bias\n",
    "\n",
    "i1, i2 = 0.05, 0.10  \n",
    "b1, b2 = 0.35, 0.60\n",
    "w1, w2, w3, w4 = 0.15, 0.20, 0.25, 0.30 \n",
    "w5, w6, w7, w8 = 0.40, 0.45, 0.50, 0.55 \n",
    "actual_o1, actual_o2 = 0.01, 0.99 \n",
    "learning_rate = 0.5\n",
    "\n",
    "# Hidden layer \n",
    "net_h1 = weighted_sum([i1, i2], [w1, w2], b1) \n",
    "out_h1 = sigmoid(net_h1)\n",
    "net_h2 = weighted_sum([i1, i2], [w3, w4], b1) \n",
    "out_h2 = sigmoid(net_h2)\n",
    "\n",
    "# Output layer \n",
    "net_o1 = weighted_sum([out_h1, out_h2], [w5, w6], b2) \n",
    "out_o1 = sigmoid(net_o1)\n",
    "net_o2 = weighted_sum([out_h1, out_h2], [w7, w8], b2) \n",
    "out_o2 = sigmoid(net_o2)\n",
    "\n",
    "print(\"Forward phase \")\n",
    "print(f\"prob of classs o1 : {out_o1}\")\n",
    "print(f\"prob of classs o2 : {out_o2}\")\n",
    "print(\"It is class o1\") if (out_o1 > out_o2) else print(\"It is class o2\")\n",
    "print(\"\\n\\nWeights:\")\n",
    "print(f\"W1: {w1}, W2: {w2}, W3: {w3}, W4: {w4}\")\n",
    "print(f\"W5: {w5}, W6: {w6}, W7: {w7}, W8: {w8}\")\n",
    "\n",
    "\n",
    "error_o1 = .5 * (out_o1 - actual_o1) ** 2\n",
    "error_o2 = .5 * (out_o2 - actual_o2) ** 2\n",
    "total_error = error_o1 + error_o2\n",
    "\n",
    "delta_o1 = (out_o1 - actual_o1) * sigmoid_derivative(out_o1)\n",
    "delta_o2 = (out_o2 - actual_o2) * sigmoid_derivative(out_o2)\n",
    "\n",
    "delta_h1 = (delta_o1 * w5 + delta_o2 * w7) * sigmoid_derivative(out_h1)\n",
    "delta_h2 = (delta_o1 * w6 + delta_o2 * w8) * sigmoid_derivative(out_h2)\n",
    "\n",
    "w1 -= learning_rate * delta_h1 * i1\n",
    "w2 -= learning_rate * delta_h1 * i2\n",
    "w3 -= learning_rate * delta_h2 * i1\n",
    "w4 -= learning_rate * delta_h2 * i2\n",
    "\n",
    "w5 -= learning_rate * delta_o1 * out_h1\n",
    "w6 -= learning_rate * delta_o1 * out_h2\n",
    "w7 -= learning_rate * delta_o2 * out_h1\n",
    "w8 -= learning_rate * delta_o2 * out_h2\n",
    "\n",
    "print('\\n\\nBackpropagation')\n",
    "print(\"Updated Weights:\")\n",
    "print(f\"W1: {w1}, W2: {w2}, W3: {w3}, W4: {w4}\")\n",
    "print(f\"W5: {w5}, W6: {w6}, W7: {w7}, W8: {w8}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
